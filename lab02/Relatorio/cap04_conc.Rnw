% ----------------------------------------------------------------------
% CAPÍTULO 5 - CONCLUSÃO
% ----------------------------------------------------------------------

Os resultados mostraram que, neste problema, considerando poucos exemplos, a acurácia mais alta foi observada para LDA e kNN. Ou seja, este estudo sugere que com poucos dados disponíveis para treinamento estas escolhas são atrativas. O estudo sugere ainda que, para este problema, um lote de exemplos superior a 9 mil não traz grandes benefícios no treino dos algoritmos. Quanto a velocidade de classificação das 58646 unidades para teste, a única que se mostrou demorada foi o kNN, tomando aproximadamente 3 minutos na plataforma Google Colab. Os demais classificadores se mostraram bastante rápidos.

Quanto à acurácia dos classificadores testados verificou-se um desempenho superior do kNN, seguido pela LDA, regressão logística e Naive Bayes. O kNN apresentou boa escalabilidade de acurácia e uma grande estabilidade. Como esperado, o LDA apresentou comportamento bastante similar ao kNN, porém levemente inferior. Comparado aos demais, a regressão logística se mostrou sensível ao tamanho da base de treino, necessitando de uma base maior para atingir acurácia à altura dos demais. Notou-se também que, para bases pequenas de treinamento, regressão logística foi inferior ao Naive Bayes; contudo, para bases maiores, este padrão se inverte. O Perceptron apresentou grandes oscilações conforme alterava-se o tamanho da base, mas no cenário com toda a base de treinamento, se mostrou como o melhor classificador para o problema.

Considerando toda a base de aprendizagem, Perceptron e kNN apresentam acurácia bastante similar. Notou-se que o Perceptron oscilou consideravelmente, mas parece apresentar uma acurácia crescente e estabilizando, sugerindo que é um bom candidato para bases de treinamento mais volumosas. O kNN, por sua vez, se mostrou mais estável. Deste modo, uma escolha segura seria o kNN, uma escolha mais arriscada e que necessitaria de mais dados para treino seria o Perceptron. Além disso, estes classificadores se mostraram complementares, dando indídio de que uma combinação entre eles pode gerar um classificador mais poderoso para o problema em questão.

Por fim, vale ressaltar que esta análise foi meramente exploratória e para um estudo mais consistente o ideal seria trabalhar com replicação, isto é, em vez de selecionar lotes de mil da base fornecida, selecionar mil linhas ao acaso, obter os modelos, acurácia e repetir este procedimento algumas vezes para cada modelo. Deste modo seria possível obter estimativas pontuais e intervalares da acurácia para cada cenário, fornecendo uma ideia mais realista de quais deles são mais estáveis.
